{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for generating reliability field maps and gradient flow vectors:\n",
    "\n",
    "## Reliability Field maps:  \n",
    "Field maps show the contribution of the intra (x-axis) and inter (y-axis) variation to the ICC in a two dimensional histogram.\n",
    "\n",
    "The field maps can be created using any measurable variable, but we focus on edges from a functional connectivity matrix. For a given edge, we plot the intra- and inter-variation on the x- and y-axis respectively revealing ICC (intra- and between-variation) via diagonal lines originating from point 0,0 in a rainbow-like manner. \n",
    "\n",
    "## Gradient flow vectors:\n",
    "Built upon the variability field map, we also utilize the variability gradient flow map (GFM) for assessing the relative impact of reliability optimizations focused on one form of variation versus the other, depending on the current balance of the intra- and inter-individual variations. This allows us to identify how and where the difference in variability between two conditions changes in an optimal or sub-optimal direction towards the highest \n",
    "\n",
    "The gradient vector on the field map represents the optimal direction for maximal ICC change on the respective axes of individual variability. For a given ICC change, we normalized its gradient by the contributions of individual variability as compared to the optimal direction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import functions needed for field maps and gradient flow vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os,sys\n",
    "import cifti\n",
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import surface,plotting\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "sys.path.append('../reliability')\n",
    "from gradient_flow_vectors import *\n",
    "from reliability_field_maps import *\n",
    "from variability_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load colormaps and set gradient flow vector options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used:\n",
    " * Functional\n",
    "     * Every edge from the upper triangle of a 360 x 360 functional connectivity matrix was used as input for the ICC model.\n",
    "         * N<sub>subs</sub> x edges from upper triangle of functional connectivity matrix\n",
    "     * The output arrays generated from the ICC model along with our specific data dictionary keys are listed below: \n",
    "         * ICC ('icc')\n",
    "         * raw intra-individual variation ('raww')\n",
    "         * raw inter-individual variation ('rawb')\n",
    "         * total variation ('vartotal')\n",
    "         * mask of failed edges ('totmask')\n",
    "     * Also included are masked arrays which exclude failed edges. \n",
    "         * 'icc_masked', 'raww_masked', 'rawb_masked', 'vartotal_masked', 'totmask_masked'\n",
    " * Behavioral\n",
    "     * N<sub>subs</sub> x 68 behavioral measures “Cognition”, “Emotion”, “Personality” (check “Motor” and “Sensory”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove masked and unused data\n",
    "## Change masking to binary\n",
    "## data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task conditions in data variable: ['REST_nogsr', 'REST_gsr']\n",
      "Dictionary keys within each task condition: ['rawb', 'raww', 'icc', 'vartotal', 'totmask']\n"
     ]
    }
   ],
   "source": [
    "# Load Data:\n",
    "data = np.load('../tutorial/example_data/tutorial_data.npy',allow_pickle=True).item()\n",
    "tasks = [task for task in data.keys()]\n",
    "print('Task conditions in data variable: %s' % tasks)\n",
    "print('Dictionary keys within each task condition: %s' % [data_keys for data_keys in data[tasks[0]].keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First obtain descriptives on GSR and no GSR ICC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'icc_masked'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0f2c696f5668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s ICC mean: %s +/- %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'icc_masked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'icc_masked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s Inter-individual variation mean: %s +/- %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rawb_masked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rawb_masked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s Intra-individual variation mean: %s +/- %s\\n '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raww_masked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raww_masked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'icc_masked'"
     ]
    }
   ],
   "source": [
    "for task in data.keys():\n",
    "    print('%s ICC mean: %s +/- %s' % (task,np.mean(data[task]['icc_masked']),np.std(data[task]['icc_masked'])))\n",
    "    print('%s Inter-individual variation mean: %s +/- %s' % (task,np.mean(data[task]['rawb_masked']),np.std(data[task]['rawb_masked'])))\n",
    "    print('%s Intra-individual variation mean: %s +/- %s\\n ' % (task,np.mean(data[task]['raww_masked']),np.std(data[task]['raww_masked'])))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resting-state scans processed with GSR have greater mean ICC (0.34 +/- 0.17) compared to scans processed without GSR (0.33 +/- 0.17)\n",
    "\n",
    "In the following, we look at how inter- and intra-individual variation contribute to ICC differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating reliability field maps:\n",
    " * For this tutorial we compare functional connectivity from data processed with GSR and without GSR.\n",
    " * After importing libraries we load in results generated from our relibility model, most importantly ICC, raw intra-individual variation, raw inter-individual variation which we will use for both reliability field maps and gradient flow maps.\n",
    " * Light grey lines from the origin, (0,0), mark ICC values starting from 0.1 (shallowest angled bottom line) to 0.9 (steepest most left) - ICC of 0 and 1 are the X and Y axes respectively.\n",
    " * We will first create individual field maps with the function **single_fieldmap()**.\n",
    " * Overlaying the individual field maps with just the contour lines allows visual comparison of inter- and intra-individual variation on ICC (**field_map_overlay()**).\n",
    " \n",
    " \n",
    "## 1. Individual fieldmaps for GSR and no GSR\n",
    " * _tasks_, _taskcolors_, _taskcmaps_ should include all conditions included in _data_\n",
    " * _taskcolors_ are individual colors for each task - can be hex or color name as set here\n",
    " * _taskcmaps_ should be color maps corresponding to each _task_ and _taskcolor_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add scatterplot/binplot (user adjust bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set colormaps/colors for field map contours\n",
    "tasks = ['REST_nogsr',\n",
    "         'REST_gsr']\n",
    "taskcolors = {'REST_gsr':'grey',\n",
    "              'REST_nogsr':'red'}\n",
    "taskcmaps = {'REST_gsr':'Greys',\n",
    "             'REST_nogsr':'Reds'}\n",
    "outpath = False # Not saving any figures for now\n",
    "lines = True # Show ICC lines\n",
    "alpha = 1 \n",
    "thr = 0.0001 # Our threshold for which variability values to include\n",
    "\n",
    "# Plot individual field maps:\n",
    "for num,task in enumerate(['REST_nogsr','REST_gsr']):\n",
    "    x = data[task]['raww_masked']\n",
    "    y = data[task]['rawb_masked']\n",
    "    xx1,yy1,normalized = plot_field_map(x,y,taskcolors[task],taskcmaps[task],alpha,lines,outpath,thr=0.0001,gridsize=100,\n",
    "                         overlay=False,cbar_option=True,figSize=(12,10),xyLim=95,shade=True,addContourLines=True)\n",
    "    \n",
    "    xperc = np.percentile(x,95)\n",
    "    yperc = np.percentile(y,95)\n",
    "    xy_lim = np.max([xperc,yperc])\n",
    "    xyVals = (0,xy_lim)\n",
    "    # Small bins\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.hist2d(x, y, bins=(100, 100), cmap=taskcmaps[task])\n",
    "    plt.xlim([0,xyVals[1]])\n",
    "    plt.ylim([0,xyVals[1]])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.hist2d(x, y, bins=(300, 300), cmap=taskcmaps[task])\n",
    "    plt.xlim([0,xyVals[1]])\n",
    "    plt.ylim([0,xyVals[1]])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.hist2d(x, y, bins=(500, 500), cmap=taskcmaps[task])\n",
    "    plt.xlim([0,xyVals[1]])\n",
    "    plt.ylim([0,xyVals[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Field map overlap for GSR and no GSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find matplotlib same x/y scaling function\n",
    "## Add scatterplot/binplot (user adjust bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Not saving any figures for now.\n",
    "outpath = False\n",
    "lines = True\n",
    "alpha = 1\n",
    "\n",
    "# Choosing conditions to compare:\n",
    "taskcombos = [['REST_nogsr',\n",
    "               'REST_gsr']]\n",
    "\n",
    "plot_field_map_overlay(taskcombos,data,taskcolors,taskcmaps,alpha,lines,outpath,\n",
    "                      cbar_option=True,figSize=(13,10),xlim=(0,0.025),ylim=(0,0.025),\n",
    "                     shade=False,thr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating gradient flow vector angular histograms:\n",
    " * Gradient flow vectors are useful understand optimality of change in variation with respect to improved reliability. Gradient flow angular histograms show the frequency of edges for each angle.\n",
    " * Gradient flow histograms are created using **gradient_flow_histogram()**.\n",
    "     * 1. intra- and inter-individual variation is used to calculate standardized gradient flow vectors and the count for each angle is plotted.\n",
    "     * 2. Each angle is counted and the total number is plotted according to the gradient flow circular colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired masking:\n",
    "# Input data should be masked such that each intra- and inter-individual variation value are paired between the two conditions\n",
    "bothmask = np.intersect1d(data[tasks[0]]['totmask_cortex'],data[tasks[1]]['totmask_cortex'])\n",
    "x0 = data[tasks[0]]['raww'][bothmask]\n",
    "y0 = data[tasks[0]]['rawb'][bothmask]\n",
    "icc0 = data[tasks[0]]['icc'][bothmask]\n",
    "x1 = data[tasks[1]]['raww'][bothmask]\n",
    "y1 = data[tasks[1]]['rawb'][bothmask]\n",
    "icc1 = data[tasks[1]]['icc'][bothmask]\n",
    "\n",
    "# Calculate vector parameters:\n",
    "df = calc_icc_vectors(x0,y0,x1,y1,\n",
    "                      icc0,icc1,tasks[0],tasks[1])\n",
    "theta = df['theta0'][~np.isnan(df['theta0'])]\n",
    "\n",
    "# Gradient flow histogram plot options:\n",
    "bin_threshold = 5 # degrees covered per histogram bar\n",
    "outpath = False # No saving for now.\n",
    "title = '%s - %s' % (tasks[1],tasks[0])\n",
    "\n",
    "# Plot gradient flow histogram:\n",
    "pah(theta,bin_threshold,gradientFlowCmaps['complete'],title,outpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating surface plots for ICC differences and parcel-wise gradient flow vectors:\n",
    " * Mean of ICC differences and mean gradient flow vector direction for each parcel connectivity vector (row/column of ICC/gradient flow matrix) are plotted on the cortical surface with **plot_surface_comparisons()** .\n",
    " * **calc_icc_vectors_mean()** first calculates standardized gradient flow vectors using the parcel vector mean of inter- and intra-individual differences to yield mean gradient flow vector direction for each parcel.\n",
    "     * Separate surface plots are generated for positive and negative ICC difference and gradient flow direction for clarity.\n",
    "     * Due to averaging across the parcel connectivity vector, ICC difference and gradient flow direction might not have complete congruency. \n",
    "\n",
    "## GSR vs No GSR surface\n",
    "\n",
    "Every 4 Surface plots in order shown (Left lateral, left medial, right lateral, right medial:\n",
    "1. Positive change gradient flow vectors\n",
    "2. Positive change ICC\n",
    "3. Negative change gradient flow vectors\n",
    "4. Negative change ICC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainspace.plotting import plot_hemispheres\n",
    "from brainspace.mesh.mesh_io import read_surface\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import cifti\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../code')\n",
    "from gradient_flow_vectors import convertAngle,calc_icc_vectors\n",
    "parcellation = glasserlabel\n",
    "taskcombos = [['REST_gsr','REST_nogsr']]\n",
    "for taskcombo in taskcombos:\n",
    "    for posNeg in ['positive','negative']:\n",
    "        task1 = taskcombo[0]\n",
    "        task2 = taskcombo[1]\n",
    "        # Vector angles:\n",
    "        mask1 = data[task1]['totmask']\n",
    "        mask2 = data[task2]['totmask']\n",
    "        bothMask = np.intersect1d(mask1,mask2)\n",
    "        icc0 = np.nanmean(array2mat(data[task1]['icc'],447),0)\n",
    "        icc1 = np.nanmean(array2mat(data[task2]['icc'],447),0)\n",
    "        x0 = np.nanmean(array2mat(data[task1]['raww'],447),0)\n",
    "        y0 = np.nanmean(array2mat(data[task1]['rawb'],447),0)\n",
    "        x1 = np.nanmean(array2mat(data[task2]['raww'],447),0)\n",
    "        y1 = np.nanmean(array2mat(data[task2]['rawb'],447),0)\n",
    "        df1 = calc_icc_vectors(x0,y0,x1,y1,icc0,icc1,task1,task2,mean=False)\n",
    "\n",
    "        plotname =  '%s-%s_%s_vectors' % (task2,task1,posNeg)\n",
    "        angVerts = parcel2vert(parcellation,df['theta0'])\n",
    "        posNegMask = parcel2vert(parcellation,icc1-icc0)\n",
    "        meandICC = np.mean(posNegMask,0)\n",
    "        numVertices = int(angVerts.shape[1]/2.)\n",
    "        symmetric_cmap = False\n",
    "        parcellation_mask = np.where(glasserlabel[0,:] == 0)[0]\n",
    "        angVerts[0,parcellation_mask] = np.nan\n",
    "\n",
    "label_text = ['Positive','Negative']\n",
    "# Conte surface\n",
    "lsurf = read_surface('../misc/surfaces/Conte69.L.very_inflated.10k_fs_LR.surf.gii')\n",
    "rsurf = read_surface('../misc/surfaces/Conte69.R.very_inflated.10k_fs_LR.surf.gii')\n",
    "posmask = np.ones(angVerts.shape[1])\n",
    "posmask[np.where((angVerts[0,:]<=45) | (angVerts[0,:]>=225))[0]] = np.nan\n",
    "negmask = np.ones(angVerts.shape[1])\n",
    "negmask[np.where((angVerts[0,:]>=45) & (angVerts[0,:]<=225))[0]] = np.nan\n",
    "\n",
    "vertArrays = [angVerts[0,:]*posmask,angVerts[0,:]*negmask,angVerts[0,:]]\n",
    "plot_hemispheres(lsurf, rsurf, array_name=vertArrays, size=(800, 400), \n",
    "                 cmap=[gradientFlowCmaps['warm'],gradientFlowCmaps['cold'],gradientFlowCmaps['complete']],\n",
    "                color_bar=False,interactive=False,embed_nb=True,nan_color=(1,1,1,1),\n",
    "                 color_range=(0,360),label_text=['P','N','C'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While data processed without GSR has overall greater reliability compared to data processed with GSR, we can see topological differences in different brain regions as shown by surface plots showing ICC differences as well as gradient vectors. With this information different preprocessing steps can be applied when higher reliability is desired for the target region being studied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parcel_to_yeo_colorList = [yeo_colors[i] for i in allparcels]\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df1['xdiff'][:360],df1['ydiff'][:360],\n",
    "            marker='o',s=20,alpha=0.7,color=parcel_to_yeo_colorList)\n",
    "plt.plot([-1,1],[-1,1],color='k')\n",
    "plt.plot([-1,1],[1,-1],color='k')\n",
    "plt.xlim([-0.01,0.01])\n",
    "plt.ylim([-0.01,0.01])\n",
    "plt.title('Normalized Values\\n%s - %s' % (tasks[0],tasks[1]))\n",
    "\n",
    "mask0 = ~np.isnan(df['x0'][:360])\n",
    "mask1 = ~np.isnan(df['x1'][:360])\n",
    "mutual_mask = mask0*mask1\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df1['x1'][:360][mutual_mask]-df1['x0'][:360][mutual_mask],\n",
    "            df1['y1'][:360][mutual_mask]-df1['y0'][:360][mutual_mask],\n",
    "            marker='o',s=20,alpha=0.7,color=np.array(parcel_to_yeo_colorList)[mutual_mask])\n",
    "plt.vlines(0,-1,1)\n",
    "plt.hlines(0,-1,1)\n",
    "plt.xlim([-0.01,0.01])\n",
    "plt.ylim([-0.01,0.01])\n",
    "plt.title('Raw values\\n%s - %s' % (tasks[0],tasks[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parcel_to_yeo_colorList = [yeo_colors[i] for i in allparcels]\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df['xdiff'],df['ydiff'],\n",
    "            marker='.',s=10,alpha=0.3)\n",
    "plt.plot([-1,1],[-1,1],color='k')\n",
    "plt.plot([-1,1],[1,-1],color='k')\n",
    "plt.xlim([-0.04,0.04])\n",
    "plt.ylim([-0.04,0.04])\n",
    "plt.title('Normalized Values\\n%s - %s' % (tasks[0],tasks[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cortex, subcortex, cerebellum:\n",
    "#### first 360 are cortex, next 54 are subcortex and last 33 are cerebellum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelInds = {'Cortex':[0,360],'Subcortex':[360,360+54],'Cerebellum':[360+54,360+54+33]}\n",
    "regionColors = {'Cortex':'y','Subcortex':'red','Cerebellum':'blue'}\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for num,region in enumerate(parcelInds.keys()):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "    Inds = parcelInds[region]\n",
    "    icc0 = array2mat(data[task1]['icc'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    icc1 = array2mat(data[task2]['icc'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    x0 = array2mat(data[task1]['raww'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    y0 = array2mat(data[task1]['rawb'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    x1 = array2mat(data[task2]['raww'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    y1 = array2mat(data[task2]['rawb'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    df = calc_icc_vectors(x0,y0,x1,y1,icc0,icc1,task1,task2,mean=False)\n",
    "\n",
    "    plt.scatter(df['xdiff'],df['ydiff'],\n",
    "                marker='.',s=10,alpha=0.2*(num+1),\n",
    "                color=regionColors[region],label='%s' % region)\n",
    "    plt.legend()\n",
    "    plt.plot([-1,1],[-1,1],color='k',lw=0.1,alpha=1)\n",
    "    plt.plot([-1,1],[1,-1],color='k',lw=0.1,alpha=1)\n",
    "    plt.xlim([-0.04,0.04])\n",
    "    plt.ylim([-0.04,0.04])\n",
    "    plt.title('Normalized Values\\n%s - %s' % (tasks[0],tasks[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelInds = {'Cortex':[0,360],'Subcortex':[360,360+54],'Cerebellum':[360+54,360+54+33]}\n",
    "regionColors = {'Cortex':'y','Subcortex':'red','Cerebellum':'blue'}\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for num,region in enumerate(parcelInds.keys()):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "    Inds = parcelInds[region]\n",
    "    icc0 = array2mat(data[task1]['icc'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    icc1 = array2mat(data[task2]['icc'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    x0 = array2mat(data[task1]['raww'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    y0 = array2mat(data[task1]['rawb'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    x1 = array2mat(data[task2]['raww'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    y1 = array2mat(data[task2]['rawb'],447)[Inds[0]:Inds[1],:][:,Inds[0]:Inds[1]]\n",
    "    df = calc_icc_vectors(x0,y0,x1,y1,icc0,icc1,task1,task2,mean=False)\n",
    "\n",
    "    plt.scatter(df['x1']-df['x0'],df['y1']-df['y0'],\n",
    "                marker='.',s=10,alpha=0.2*(num+1),\n",
    "                color=regionColors[region],label='%s' % region)\n",
    "    plt.legend()\n",
    "    plt.vlines(0,-1,1,color='k',lw=0.1,alpha=1)\n",
    "    plt.hlines(0,-1,1,color='k',lw=0.1,alpha=1)\n",
    "    plt.xlim([-0.04,0.04])\n",
    "    plt.ylim([-0.04,0.04])\n",
    "    plt.title('Raw Values\\n%s - %s' % (tasks[0],tasks[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = 'REST_nogsr'\n",
    "task2 = 'REST_gsr'\n",
    "icc0 = data[task1]['icc']\n",
    "icc1 = data[task2]['icc']\n",
    "x0 = data[task1]['raww']\n",
    "y0 = data[task1]['rawb']\n",
    "x1 = data[task2]['raww']\n",
    "y1 = data[task2]['rawb']\n",
    "df1 = calc_icc_vectors(x0,y0,x1,y1,icc0,icc1,task1,task2,mean=False)\n",
    "# tingFile = pd.read_csv('/Users/jaewook.cho/Downloads/Demo_HCP_REST1_LR_GSR_vs_noGSR.csv')\n",
    "tingFile = pd.read_csv('/Users/jaewook.cho/Downloads/example_data_HCP_REST1_LR_GSR_vs_noGSR.csv')\n",
    "np.sum(df1['theta0']!=np.degrees(tingFile['delta.theta'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(tingFile['delta.theta_norm'].values))\n",
    "radAng = np.radians(df1['theta0'])\n",
    "radAng[np.isnan(radAng)] = 0\n",
    "tingAng = tingFile['delta.theta_norm'].values\n",
    "np.sum(radAng!=tingAng)/len(tingAng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task1,np.nanmean(icc0))\n",
    "print(task2,np.nanmean(icc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(tingFile['delta.sigma2_w'].values,tingFile['delta.sigma2_b'].values,s=10,marker='.')\n",
    "plt.xlim([-0.05,0.05])\n",
    "plt.ylim([-0.05,0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df1['xdiff'],df1['ydiff'],s=10,marker='.')\n",
    "plt.xlim([-0.05,0.05])\n",
    "plt.ylim([-0.05,0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tingAng_nonan = np.degrees(tingFile['delta.theta_norm'])\n",
    "tingAng_nonan = tingAng_nonan[~np.isnan(tingAng_nonan)]\n",
    "pah(tingAng_nonan,bin_threshold,gradientFlowCmaps['complete'],title,outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang_nonan = df1['theta0'][:64620][np.intersect1d(data[task1]['totmask_cortex'],data[task2]['totmask_cortex'])]\n",
    "# ang_nonan[~np.isnan(ang_nonan)]\n",
    "pah(ang_nonan,bin_threshold,gradientFlowCmaps['complete'],title,outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
