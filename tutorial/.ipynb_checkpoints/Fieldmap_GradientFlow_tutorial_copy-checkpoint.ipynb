{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for generating reliability field maps and gradient flow vectors:\n",
    "\n",
    "## Reliability Field maps:  \n",
    "Field maps show the contribution of the intra (x-axis) and inter (y-axis) variation to the ICC in a two dimensional histogram.\n",
    "\n",
    "The field maps can be created using any measurable variable, but we focus on edges from a functional connectivity matrix. For a given edge, we plot the intra- and inter-variation on the x- and y-axis respectively revealing ICC (intra- and between-variation) via diagonal lines originating from point 0,0 in a rainbow-like manner. \n",
    "\n",
    "## Gradient flow vectors:\n",
    "Built upon the variability field map, we also utilize the variability gradient flow map (GFM) for assessing the relative impact of reliability optimizations focused on one form of variation versus the other, depending on the current balance of the intra- and inter-individual variations. This allows us to identify how and where the difference in variability between two conditions changes in an optimal or sub-optimal direction towards the highest \n",
    "\n",
    "The gradient vector on the field map represents the optimal direction for maximal ICC change on the respective axes of individual variability. For a given ICC change, we normalized its gradient by the contributions of individual variability as compared to the optimal direction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import functions needed for field maps and gradient flow vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os,sys\n",
    "import cifti\n",
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import surface,plotting\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "sys.path.append('../code')\n",
    "from gradient_flow_vectors import *\n",
    "from reliability_field_maps import *\n",
    "from variability_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load surfaces to plot ICC differences and gradient flow vectors on the surface\n",
    "\n",
    "* Put prior to surface plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conte surface\n",
    "lsurf = surface.load_surf_mesh('../misc/surfaces/Conte69.L.very_inflated.10k_fs_LR.surf.gii')\n",
    "rsurf = surface.load_surf_mesh('../misc/surfaces/Conte69.R.very_inflated.10k_fs_LR.surf.gii')\n",
    "\n",
    "# Surface plot background\n",
    "bg = nib.load('../misc/surfaces/100206.sulc.10k_fs_LR.dscalar.nii').get_fdata()\n",
    "\n",
    "# Example file to save surface plots\n",
    "plabel = '../misc/Glasser2016_labels/HCP_MMP_P210_10k.dlabel.nii'\n",
    "glasserlabel,(ax1,ax2) = cifti.read(plabel)\n",
    "numverts = glasserlabel.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load colormaps and set gradient flow vector options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colormaps\n",
    "# rvb = vector_cmap() # Gradient flow vector colormap\n",
    "rvb = icc_gradient_flow_cmap()\n",
    "# yeo_colors = get_yeo_colors() # Yeo 7 network colors in RGB (turned into global variable)\n",
    "allparcels = get_yeo_parcels() # Glasser 360 parcels to Yeo 7 network assignments\n",
    "\n",
    "# Vector plot options:\n",
    "outpath = False\n",
    "vector_type = 'norm_0' # raw, norm, norm_0\n",
    "alpha = 1 # plot option\n",
    "# savefolder = '../figures'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used:\n",
    " * Functional\n",
    "     * Every edge from the upper triangle of a 360 x 360 functional connectivity matrix was used as input for the ICC model.\n",
    "         * N<sub>subs</sub> x edges from upper triangle of functional connectivity matrix\n",
    "     * The output arrays generated from the ICC model along with our specific data dictionary keys are listed below: \n",
    "         * ICC ('icc')\n",
    "         * raw intra-individual variation ('raww')\n",
    "         * raw inter-individual variation ('rawb')\n",
    "         * total variation ('vartotal')\n",
    "         * mask of failed edges ('totmask')\n",
    "     * Also included are masked arrays which exclude failed edges. \n",
    "         * 'icc_masked', 'raww_masked', 'rawb_masked', 'vartotal_masked', 'totmask_masked'\n",
    " * Behavioral\n",
    "     * N<sub>subs</sub> x 68 behavioral measures “Cognition”, “Emotion”, “Personality” (check “Motor” and “Sensory”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove masked and unused data\n",
    "## Change masking to binary\n",
    "## data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task conditions in data variable: ['REST_nogsr', 'REST_gsr']\n",
      "Dictionary keys within each task condition: ['rawb', 'raww', 'icc', 'vartotal', 'totmask', 'totmask_cortex', 'raww_masked', 'rawb_masked', 'icc_masked', 'vartotal_masked']\n"
     ]
    }
   ],
   "source": [
    "# Load Data:\n",
    "data = np.load('../tutorial/example_data/tutorial_data.npy',allow_pickle=True).item()\n",
    "tasks = [task for task in data.keys()]\n",
    "print('Task conditions in data variable: %s' % tasks)\n",
    "print('Dictionary keys within each task condition: %s' % [data_keys for data_keys in data[tasks[0]].keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First obtain descriptives on GSR and no GSR ICC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REST_nogsr ICC mean: 0.3269461615406128 +/- 0.16618663921606122\n",
      "REST_nogsr Inter-individual variation mean: 0.0064448203904029985 +/- 0.004434554694389156\n",
      "REST_nogsr Intra-individual variation mean: 0.012462686539650639 +/- 0.004424689651843456\n",
      " \n",
      "REST_gsr ICC mean: 0.33925891966189664 +/- 0.17487204079738128\n",
      "REST_gsr Inter-individual variation mean: 0.00884100229180252 +/- 0.006779597231439544\n",
      "REST_gsr Intra-individual variation mean: 0.015227109999291203 +/- 0.005133726686205739\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for task in data.keys():\n",
    "    print('%s ICC mean: %s +/- %s' % (task,np.mean(data[task]['icc_masked']),np.std(data[task]['icc_masked'])))\n",
    "    print('%s Inter-individual variation mean: %s +/- %s' % (task,np.mean(data[task]['rawb_masked']),np.std(data[task]['rawb_masked'])))\n",
    "    print('%s Intra-individual variation mean: %s +/- %s\\n ' % (task,np.mean(data[task]['raww_masked']),np.std(data[task]['raww_masked'])))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resting-state scans processed with GSR have greater mean ICC (0.34 +/- 0.17) compared to scans processed without GSR (0.33 +/- 0.17)\n",
    "\n",
    "In the following, we look at how inter- and intra-individual variation contribute to ICC differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating reliability field maps:\n",
    " * For this tutorial we compare functional connectivity from data processed with GSR and without GSR.\n",
    " * After importing libraries we load in results generated from our relibility model, most importantly ICC, raw intra-individual variation, raw inter-individual variation which we will use for both reliability field maps and gradient flow maps.\n",
    " * Light grey lines from the origin, (0,0), mark ICC values starting from 0.1 (shallowest angled bottom line) to 0.9 (steepest most left) - ICC of 0 and 1 are the X and Y axes respectively.\n",
    " * We will first create individual field maps with the function **single_fieldmap()**.\n",
    " * Overlaying the individual field maps with just the contour lines allows visual comparison of inter- and intra-individual variation on ICC (**field_map_overlay()**).\n",
    " \n",
    " \n",
    "## 1. Individual fieldmaps for GSR and no GSR\n",
    " * _tasks_, _taskcolors_, _taskcmaps_ should include all conditions included in _data_\n",
    " * _taskcolors_ are individual colors for each task - can be hex or color name as set here\n",
    " * _taskcmaps_ should be color maps corresponding to each _task_ and _taskcolor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as mcm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from seaborn.utils import iqr, _kde_support, remove_na\n",
    "\n",
    "from six import string_types\n",
    "\n",
    "# Calculate KDE for field maps:\n",
    "def _scipy_bivariate_kde(x, y, bw, gridsize, cut, clip):\n",
    "\n",
    "    \"\"\"Compute a bivariate kde using scipy.\"\"\"\n",
    "    \n",
    "    data = np.c_[x, y]\n",
    "    kde = stats.gaussian_kde(data.T, bw_method=bw)\n",
    "    data_std = data.std(axis=0, ddof=1)\n",
    "    if isinstance(bw, string_types):\n",
    "        bw = \"scotts\" if bw == \"scott\" else bw\n",
    "        bw_x = getattr(kde, \"%s_factor\" % bw)() * data_std[0]\n",
    "        bw_y = getattr(kde, \"%s_factor\" % bw)() * data_std[1]\n",
    "    elif np.isscalar(bw):\n",
    "        bw_x, bw_y = bw, bw\n",
    "    else:\n",
    "        msg = (\"Cannot specify a different bandwidth for each dimension \"\n",
    "               \"with the scipy backend. You should install statsmodels.\")\n",
    "        raise ValueError(msg)\n",
    "    x_support = _kde_support(data[:, 0], bw_x, gridsize, cut, clip[0])\n",
    "    y_support = _kde_support(data[:, 1], bw_y, gridsize, cut, clip[1])\n",
    "    xx, yy = np.meshgrid(x_support, y_support)\n",
    "    z = kde([xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    return xx, yy, z\n",
    "\n",
    "# KDE plot function:\n",
    "def _bivariate_kdeplot(xx1, yy1, z1scale, filled, fill_lowest,\n",
    "                       kernel, bw, gridsize, cut, clip,\n",
    "                       axlabel, cbar, cbar_ax, cbar_kws, ax, **kwargs):\n",
    "    from seaborn.palettes import color_palette, light_palette, dark_palette, blend_palette\n",
    "    \"\"\"Plot a joint KDE estimate as a bivariate contour plot.\"\"\"\n",
    "    # Determine the clipping\n",
    "    if clip is None:\n",
    "        clip = [(-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "    elif np.ndim(clip) == 1:\n",
    "        clip = [clip, clip]\n",
    "    # Plot the contours\n",
    "    n_levels = kwargs.pop(\"n_levels\", 10)\n",
    "    scout, = ax.plot([], [])\n",
    "    default_color = scout.get_color()\n",
    "    scout.remove()\n",
    "    color = kwargs.pop(\"color\", default_color)\n",
    "#     cmap = kwargs.pop(\"cmap\", None)\n",
    "    cmap = cbar_kws['cmap']\n",
    "    label = kwargs.pop(\"label\", None)\n",
    "    kwargs[\"cmap\"] = cmap\n",
    "    contour_func = ax.contourf if filled else ax.contour\n",
    "    cset = contour_func(xx1, yy1, z1scale, n_levels, **kwargs)\n",
    "    if filled and not fill_lowest:\n",
    "        cset.collections[0].set_alpha(0)\n",
    "    kwargs[\"n_levels\"] = n_levels\n",
    "    if cbar:\n",
    "        cbar_kws = {} if cbar_kws is None else cbar_kws\n",
    "        ax.figure.colorbar(cset, cbar_ax, ax, **cbar_kws)\n",
    "    # Label the axes\n",
    "    if hasattr(xx1, \"name\") and axlabel:\n",
    "        ax.set_xlabel(x.name)\n",
    "    if hasattr(yy1, \"name\") and axlabel:\n",
    "        ax.set_ylabel(y.name)\n",
    "    if label is not None:\n",
    "        legend_color = cmap(.95) if color is None else color\n",
    "        if filled:\n",
    "            ax.fill_between([], [], color=legend_color, label=label)\n",
    "        else:\n",
    "            ax.plot([], [], color=legend_color, label=label)\n",
    "    return ax\n",
    "\n",
    "def plot_field_map(x,y,taskcolor,taskcmap,alpha,lines,outpath,thr=0.0001,gridsize=300,\n",
    "                     overlay=False,cbar_option=True,figSize=(12,10),xyLim=95,shade=True,addContourLines=True):\n",
    "    \n",
    "    plt.figure(figsize=(figSize[0],figSize[1]))\n",
    "    sns.set_style('white')\n",
    "    ax=plt.gca()\n",
    "    mpl.rcParams['font.weight'] = 'bold'\n",
    "    mpl.rcParams['font.size'] = 1\n",
    "    sns.set(font_scale=3)\n",
    "    \n",
    "    if int(xyLim):\n",
    "        xperc = np.percentile(x,xyLim)\n",
    "        yperc = np.percentile(y,xyLim)\n",
    "        xy_lim = np.max([xperc,yperc])\n",
    "        xyVals = (0,xy_lim)\n",
    "    elif type(xyLim) == 'tuple':\n",
    "        xyVals = (xyLim[0],xyLim[1])\n",
    "\n",
    "    ax.axes.set_xlim([xyVals[0],xyVals[1]])\n",
    "    ax.axes.set_ylim([xyVals[0],xyVals[1]])\n",
    "    plt.xticks(fontweight='bold',fontsize=20)\n",
    "    plt.yticks(fontweight='bold',fontsize=20)\n",
    "    plt.xlabel('Intra-individual Variation',labelpad=20,fontweight='bold',fontsize=20)\n",
    "    plt.ylabel('Inter-individual Variation',labelpad=20,fontweight='bold',fontsize=20)\n",
    "    bw='scott'\n",
    "    gridsize=gridsize\n",
    "    cut=10\n",
    "    clip = [(-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "    legend=True\n",
    "    cumulative=False\n",
    "    shade=shade\n",
    "    shade_lowest=False\n",
    "    cbar=False\n",
    "    cbar_ax=None\n",
    "    filled=True\n",
    "    fill_lowest=False\n",
    "    vertical=False\n",
    "    kernel=\"gau\"\n",
    "\n",
    "    # Kde distribution:\n",
    "    xx1, yy1, z1 = _scipy_bivariate_kde(x, y, bw, gridsize, cut, clip)\n",
    "\n",
    "    # Scaling and normalization so that field maps are comparable:\n",
    "    scaler = float(1000) # Take this out and just make sure line 225 is float\n",
    "    z1scale = scaler*z1/np.sum(z1)\n",
    "    normalized = (z1scale-np.min(z1scale))/(np.max(z1scale)-np.min(z1scale))\n",
    "    \n",
    "#     # Find max x,y density:\n",
    "#     maxXY = np.where(normalized == np.max(normalized))\n",
    "#     print(maxXY)\n",
    "    # Reset clip for actual kdeplot:\n",
    "    clip=None\n",
    "\n",
    "    # Set colorbar for scaled density plot:\n",
    "    cbar_kws={'cmap':taskcmap}\n",
    "    our_cmap = plt.get_cmap(taskcmap)\n",
    "    cmap_max = 1.00001\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=cmap_max)    \n",
    "    proxy_mappable = mpl.cm.ScalarMappable(cmap=our_cmap, norm=norm)\n",
    "    proxy_mappable.set_array(normalized)   \n",
    "    ax = _bivariate_kdeplot(xx1, yy1, normalized, shade, \n",
    "                            shade_lowest, kernel, bw, gridsize, \n",
    "                            cut, clip, legend, cbar, cbar_ax, cbar_kws, \n",
    "                            ax,vmin=0,vmax=cmap_max,levels=5,alpha=alpha,\n",
    "                           linewidths=5)\n",
    "    if addContourLines == True:\n",
    "        ax = plt.contour(xx1,yy1,normalized,5,colors = taskcolor)\n",
    "    if cbar_option == True:\n",
    "        cbar = plt.colorbar(proxy_mappable, boundaries=np.arange(0,cmap_max,.1), spacing='proportional', orientation='vertical', pad=.01)\n",
    "        cbar.set_label('Density',labelpad=20)\n",
    "\n",
    "    if lines == True:\n",
    "        plt.plot([1,0],[1,0],color='black',alpha=0.3,zorder=0)\n",
    "        for iccline in [0.2,0.4,0.6,0.8]:\n",
    "#             plt.plot([1,0],[iccline,0],color='black',alpha=0.3,zorder=len(taskcombos)+1)\n",
    "#             plt.plot([iccline,0],[1,0],color='black',alpha=0.3,zorder=len(taskcombos)+1) \n",
    "            plt.plot([1,0],[iccline,0],color='black',alpha=0.3)\n",
    "            plt.plot([iccline,0],[1,0],color='black',alpha=0.3) \n",
    "\n",
    "    if outpath == True:\n",
    "        plt.savefig('../figures/shortpaper/fieldmaps/%s_%s_perc%s_fieldmap_nogsr_front_contour_070121_time_1200-600.png' % (taskcombo[0],taskcombo[1],percnum),dpi=300)\n",
    "    plt.show()   \n",
    "    return xx1,yy1,normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set colormaps/colors for field map contours\n",
    "tasks = ['REST_nogsr',\n",
    "         'REST_gsr']\n",
    "taskcolors = {'REST_gsr':'grey',\n",
    "              'REST_nogsr':'red'}\n",
    "taskcmaps = {'REST_gsr':'Greys',\n",
    "             'REST_nogsr':'Reds'}\n",
    "outpath = False # Not saving any figures for now\n",
    "lines = True # Show ICC lines\n",
    "alpha = 1 \n",
    "thr = 0.0001 # Our threshold for which variability values to include\n",
    "\n",
    "# Plot individual field maps:\n",
    "for num,task in enumerate(['REST_nogsr','REST_gsr']):\n",
    "    x = data[task]['raww_masked']\n",
    "    y = data[task]['rawb_masked']\n",
    "    xx1,yy1,normalized = plot_field_map(x,y,taskcolors[task],taskcmaps[task],alpha,lines,outpath,thr=0.0001,gridsize=50,\n",
    "                         overlay=False,cbar_option=True,figSize=(12,10),xyLim=95,shade=True,addContourLines=True)\n",
    "    \n",
    "    xperc = np.percentile(x,95)\n",
    "    yperc = np.percentile(y,95)\n",
    "    xy_lim = np.max([xperc,yperc])\n",
    "    xyVals = (0,xy_lim)\n",
    "    # Small bins\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.hist2d(x, y, bins=(100, 100), cmap=taskcmaps[task])\n",
    "    plt.xlim([0,xyVals[1]])\n",
    "    plt.ylim([0,xyVals[1]])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.hist2d(x, y, bins=(300, 300), cmap=taskcmaps[task])\n",
    "    plt.xlim([0,xyVals[1]])\n",
    "    plt.ylim([0,xyVals[1]])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.hist2d(x, y, bins=(500, 500), cmap=taskcmaps[task])\n",
    "    plt.xlim([0,xyVals[1]])\n",
    "    plt.ylim([0,xyVals[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Field map overlap for GSR and no GSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Not saving any figures for now.\n",
    "# outpath = False\n",
    "# lines = True\n",
    "# alpha = 1\n",
    "\n",
    "# # Choosing conditions to compare:\n",
    "# taskcombos = [['REST_nogsr',\n",
    "#                'REST_gsr']]\n",
    "\n",
    "# plot_field_map_overlay(taskcombos,data,taskcolors,taskcmaps,alpha,lines,outpath,\n",
    "#                       cbar_option=True,figSize=(12,10),xlim=(0,0.025),ylim=(0,0.025),\n",
    "#                      shade=False,thr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating gradient flow vector angular histograms:\n",
    " * Gradient flow vectors are useful understand optimality of change in variation with respect to improved reliability. Gradient flow angular histograms show the frequency of edges for each angle.\n",
    " * Gradient flow histograms are created using **gradient_flow_histogram()**.\n",
    "     * 1. intra- and inter-individual variation is used to calculate standardized gradient flow vectors and the count for each angle is plotted.\n",
    "     * 2. Each angle is counted and the total number is plotted according to the gradient flow circular colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Paired masking:\n",
    "# # Input data should be masked such that each intra- and inter-individual variation value are paired between the two conditions\n",
    "# bothmask = np.intersect1d(data[tasks[0]]['totmask_cortex'],data[tasks[1]]['totmask_cortex'])\n",
    "# x0 = data[tasks[0]]['raww'][bothmask]\n",
    "# y0 = data[tasks[0]]['rawb'][bothmask]\n",
    "# icc0 = data[tasks[0]]['icc'][bothmask]\n",
    "# x1 = data[tasks[1]]['raww'][bothmask]\n",
    "# y1 = data[tasks[1]]['rawb'][bothmask]\n",
    "# icc1 = data[tasks[1]]['icc'][bothmask]\n",
    "\n",
    "# # Calculate vector parameters:\n",
    "# df = calc_icc_vectors(x0,y0,x1,y1,\n",
    "#                       icc0,icc1,tasks[0],tasks[1])\n",
    "# theta = np.array([convertAngle(df['theta0'][i],df['xdiff'][i]) for i in range(len(df['theta0']))])\n",
    "# theta = theta[~np.isnan(theta)]\n",
    "\n",
    "# # Gradient flow histogram plot options:\n",
    "# bin_threshold = 5 # degrees covered per histogram bar\n",
    "# outpath = False # No saving for now.\n",
    "# title = False # No title for now.\n",
    "\n",
    "# # Plot gradient flow histogram:\n",
    "# pah(theta,bin_threshold,rvb,title,outpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating surface plots for ICC differences and parcel-wise gradient flow vectors:\n",
    " * Mean of ICC differences and mean gradient flow vector direction for each parcel connectivity vector (row/column of ICC/gradient flow matrix) are plotted on the cortical surface with **plot_surface_comparisons()** .\n",
    " * **calc_icc_vectors_mean()** first calculates standardized gradient flow vectors using the parcel vector mean of inter- and intra-individual differences to yield mean gradient flow vector direction for each parcel.\n",
    "     * Separate surface plots are generated for positive and negative ICC difference and gradient flow direction for clarity.\n",
    "     * Due to averaging across the parcel connectivity vector, ICC difference and gradient flow direction might not have complete congruency. \n",
    "\n",
    "## GSR vs No GSR surface\n",
    "\n",
    "Every 4 Surface plots in order shown (Left lateral, left medial, right lateral, right medial:\n",
    "1. Positive change gradient flow vectors\n",
    "2. Positive change ICC\n",
    "3. Negative change gradient flow vectors\n",
    "4. Negative change ICC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #############################################################\n",
    "# # make positive and negative cmaps instead of changing data #\n",
    "# #############################################################\n",
    "# taskcombos = [['REST_gsr','REST_nogsr']]\n",
    "# outpath = None\n",
    "# numparcels = 1\n",
    "# alpha = 1\n",
    "# glasserlabel,(ax1,ax2) = cifti.read(plabel)\n",
    "# surfaces = [lsurf,rsurf]\n",
    "# numparcels = 1\n",
    "# alpha = 1\n",
    "# darkness = 0.1\n",
    "# data_range = (0,360)\n",
    "# cmap = rvb\n",
    "# parcellation = glasserlabel\n",
    "# outpath = False\n",
    "# plot_surface_comparisons(taskcombos, data, parcellation, surfaces, numparcels, alpha, darkness, data_range,cmap,outpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While data processed without GSR has overall greater reliability compared to data processed with GSR, we can see topological differences in different brain regions as shown by surface plots showing ICC differences as well as gradient vectors. With this information different preprocessing steps can be applied when higher reliability is desired for the target region being studied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import cifti\n",
    "# import matplotlib.pyplot as plt\n",
    "# sys.path.append('../code')\n",
    "# from gradient_flow_vectors import calc_icc_vectors_mean, convertAngle,calc_icc_vectors\n",
    "# lsurf = surfaces[0]\n",
    "# rsurf = surfaces[1]\n",
    "# for taskcombo in taskcombos:\n",
    "#     for posNeg in ['positive','negative']:\n",
    "#         task1 = taskcombo[0]\n",
    "#         task2 = taskcombo[1]\n",
    "#         # Vector angles:\n",
    "#         mask1 = data[task1]['totmask']\n",
    "#         mask2 = data[task2]['totmask']\n",
    "#         bothMask = np.intersect1d(mask1,mask2)\n",
    "#         icc0 = np.nanmean(array2mat(data[task1]['icc'],447),0)[0]\n",
    "#         icc1 = np.nanmean(array2mat(data[task2]['icc'],447),0)[0]\n",
    "#         x0 = np.nanmean(array2mat(data[task1]['raww'],447),0)[0]\n",
    "#         y0 = np.nanmean(array2mat(data[task1]['rawb'],447),0)[0]\n",
    "#         x1 = np.nanmean(array2mat(data[task2]['raww'],447),0)[0]\n",
    "#         y1 = np.nanmean(array2mat(data[task2]['rawb'],447),0)[0]\n",
    "#         df = calc_icc_vectors(x0,y0,x1,y1,icc0,icc1,task1,task2)\n",
    "\n",
    "#         plotname =  '%s-%s_%s_vectors' % (task2,task1,posNeg)\n",
    "#         converted_angles = np.array([convertAngle(df['theta0'][i],df['xdiff'][i]) for i in range(len(df['theta0']))])\n",
    "#         angVerts = parcel2vert(parcellation,converted_angles)\n",
    "#         posNegMask = parcel2vert(parcellation,icc1-icc0)\n",
    "#         meandICC = np.mean(posNegMask,0)\n",
    "#         numVertices = int(angVerts.shape[1]/2.)\n",
    "#         symmetric_cmap = False\n",
    "#         parcellation_mask = np.where(glasserlabel[0,:] == 0)[0]\n",
    "#         angVerts[0,parcellation_mask] = np.nan\n",
    "\n",
    "# warm_cmap_whites,cold_cmap_whites = warm_cold_gradient_flow_cmap()\n",
    "# # testarray = np.ones([1,20484]) * 300\n",
    "# # testarray[0,parcellation_mask] = 45\n",
    "# numVertices = int(angVerts.shape[1]/2.)\n",
    "# symmetric_cmap = False\n",
    "# plot_surface(angVerts,lsurf,rsurf,numVertices,data_range,warm_cmap_whites,alpha,\n",
    "#                          darkness,symmetric_cmap,False,outpath,'%s-%s_%s_dICC_angle' % (task2,task1,posNeg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from brainspace.plotting import plot_hemispheres\n",
    "# from brainspace.mesh.mesh_io import read_surface\n",
    "# from brainspace.datasets import load_conte69\n",
    "# %matplotlib inline\n",
    "# # Conte surface\n",
    "# lsurf = read_surface('../misc/surfaces/Conte69.L.very_inflated.10k_fs_LR.surf.gii')\n",
    "# rsurf = read_surface('../misc/surfaces/Conte69.R.very_inflated.10k_fs_LR.surf.gii')\n",
    "# plot_hemispheres(lsurf, rsurf, array_name=angVerts, size=(800, 200),cmap=warm_cmap_whites,\n",
    "#                 color_bar=False,interactive=False,embed_nb=True,nan_color=(1,1,1,1))\n",
    "# plot_hemispheres(lsurf, rsurf, array_name=angVerts, size=(800, 200),cmap=cold_cmap_whites,\n",
    "#                 color_bar=False,interactive=False,embed_nb=True,nan_color=(1,1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
